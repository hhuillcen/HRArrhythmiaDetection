{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv('/content/dataset_fc.csv')  #  archivo\n",
        "\n",
        "# Convertir la columna objetivo a datos numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "df['dx_holter_final'] = label_encoder.fit_transform(df['dx_holter_final'])  # 0 para 'arritmia', 1 para 'normal'\n",
        "\n",
        "\n",
        "X = df.drop(columns=['dx_holter_final']).values\n",
        "y = df['dx_holter_final'].values\n",
        "\n",
        "# Imputar valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Balancear los datos antes de dividir\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo de regresión logística\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Definir los hiperparámetros a probar\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'max_iter': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), verbose=2, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Ajustar GridSearchCV a los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best score: {grid_search.best_score_:.4f}')\n",
        "\n",
        "# Evaluar el modelo final con los mejores hiperparámetros\n",
        "best_log_reg = grid_search.best_estimator_\n",
        "y_pred = best_log_reg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {accuracy:.4f}')\n",
        "print(f'Final Model Recall: {recall:.4f}')\n",
        "print(f'Final Model F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "\n",
        "# Realiza las predicciones\n",
        "y_pred = best_log_reg.predict(X_test)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Calcular sensibilidad (recall)\n",
        "sensitivity = recall_score(y_test, y_pred)\n",
        "print(f'Sensibilidad (Recall): {sensitivity:.4f}')\n",
        "\n",
        "# Calcular especificidad\n",
        "specificity = tn / (tn + fp)\n",
        "print(f'Especificidad: {specificity:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmO3vzbaJLoJ",
        "outputId": "2c5343a8-2e00-458c-a19d-996454afe7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
            "Best parameters: {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best score: 0.7144\n",
            "Final Model Accuracy: 0.6486\n",
            "Final Model Recall: 0.5676\n",
            "Final Model F1 Score: 0.6176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARRITMIA       0.63      0.73      0.68        37\n",
            "      NORMAL       0.68      0.57      0.62        37\n",
            "\n",
            "    accuracy                           0.65        74\n",
            "   macro avg       0.65      0.65      0.65        74\n",
            "weighted avg       0.65      0.65      0.65        74\n",
            "\n",
            "Sensibilidad (Recall): 0.5676\n",
            "Especificidad: 0.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "675 fits failed out of a total of 1500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.                nan 0.53329928 0.70594005\n",
            " 0.70594005 0.70594005 0.70594005 0.70594005        nan        nan\n",
            "        nan        nan        nan 0.71186603 0.71186603        nan\n",
            " 0.71186603 0.71186603        nan        nan 0.                nan\n",
            " 0.53481444 0.70594005 0.70594005 0.70594005 0.70594005 0.70594005\n",
            "        nan        nan        nan        nan        nan 0.71186603\n",
            " 0.71186603        nan 0.71186603 0.71186603        nan        nan\n",
            " 0.                nan 0.39846782 0.70594005 0.70594005 0.70594005\n",
            " 0.70594005 0.70594005        nan        nan        nan        nan\n",
            "        nan 0.71186603 0.71186603        nan 0.71186603 0.71186603\n",
            "        nan        nan 0.70595948        nan 0.70136177 0.70485612\n",
            " 0.70485612 0.70988757 0.70485612 0.70485612        nan        nan\n",
            "        nan        nan        nan 0.71186603 0.71186603        nan\n",
            " 0.71186603 0.71186603        nan        nan 0.70595948        nan\n",
            " 0.70136177 0.70485612 0.70485612 0.70988757 0.70485612 0.70485612\n",
            "        nan        nan        nan        nan        nan 0.71186603\n",
            " 0.71186603        nan 0.71186603 0.71186603        nan        nan\n",
            " 0.70595948        nan 0.70136177 0.70485612 0.70485612 0.70988757\n",
            " 0.70485612 0.70485612        nan        nan        nan        nan\n",
            "        nan 0.71186603 0.71186603        nan 0.71186603 0.71186603\n",
            "        nan        nan 0.71404857        nan 0.71199134 0.70969697\n",
            " 0.70969697 0.70969697 0.70969697 0.70969697        nan        nan\n",
            "        nan        nan        nan 0.71186603 0.71186603        nan\n",
            " 0.71186603 0.71186603        nan        nan 0.71404857        nan\n",
            " 0.71199134 0.70969697 0.70969697 0.70969697 0.70969697 0.70969697\n",
            "        nan        nan        nan        nan        nan 0.71186603\n",
            " 0.71186603        nan 0.71186603 0.71186603        nan        nan\n",
            " 0.71404857        nan 0.71199134 0.70969697 0.70969697 0.70969697\n",
            " 0.70969697 0.70969697        nan        nan        nan        nan\n",
            "        nan 0.71186603 0.71186603        nan 0.71186603 0.71186603\n",
            "        nan        nan 0.71186603        nan 0.71437229 0.71437229\n",
            " 0.71437229 0.71437229 0.71437229 0.71437229        nan        nan\n",
            "        nan        nan        nan 0.71186603 0.71186603        nan\n",
            " 0.71186603 0.71186603        nan        nan 0.71186603        nan\n",
            " 0.71186603 0.71437229 0.71437229 0.71437229 0.71437229 0.71437229\n",
            "        nan        nan        nan        nan        nan 0.71186603\n",
            " 0.71186603        nan 0.71186603 0.71186603        nan        nan\n",
            " 0.71186603        nan 0.71437229 0.71437229 0.71437229 0.71437229\n",
            " 0.71437229 0.71437229        nan        nan        nan        nan\n",
            "        nan 0.71186603 0.71186603        nan 0.71186603 0.71186603\n",
            "        nan        nan 0.71186603        nan 0.71186603 0.71186603\n",
            " 0.71186603 0.71186603 0.71186603 0.71186603        nan        nan\n",
            "        nan        nan        nan 0.71186603 0.71186603        nan\n",
            " 0.71186603 0.71186603        nan        nan 0.71186603        nan\n",
            " 0.71186603 0.71186603 0.71186603 0.71186603 0.71186603 0.71186603\n",
            "        nan        nan        nan        nan        nan 0.71186603\n",
            " 0.71186603        nan 0.71186603 0.71186603        nan        nan\n",
            " 0.71186603        nan 0.71186603 0.71186603 0.71186603 0.71186603\n",
            " 0.71186603 0.71186603        nan        nan        nan        nan\n",
            "        nan 0.71186603 0.71186603        nan 0.71186603 0.71186603]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}