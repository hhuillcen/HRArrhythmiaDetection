{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv('/content/dataset_fc.csv')\n",
        "\n",
        "# Convertir la columna objetivo a datos numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "df['dx_holter_final'] = label_encoder.fit_transform(df['dx_holter_final'])  # 0 para 'arritmia', 1 para 'normal'\n",
        "\n",
        "\n",
        "X = df.drop(columns=['dx_holter_final']).values\n",
        "y = df['dx_holter_final'].values\n",
        "\n",
        "# Imputar valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Balancear los datos antes de dividir\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo MLP\n",
        "mlp = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Definir los hiperparámetros a probar\n",
        "param_grid = {\n",
        "    #'hidden_layer_sizes': [(50, 50), (100, 100), (150, 150)],\n",
        "    'hidden_layer_sizes': [(50,), (100,), (150,), (50, 50), (100, 100), (150, 150)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), verbose=2, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Ajustar GridSearchCV a los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best score: {grid_search.best_score_:.4f}')\n",
        "\n",
        "# Evaluar el modelo final con los mejores hiperparámetros\n",
        "best_mlp = grid_search.best_estimator_\n",
        "y_pred = best_mlp.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {accuracy:.4f}')\n",
        "print(f'Final Model Recall: {recall:.4f}')\n",
        "print(f'Final Model F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "\n",
        "# Realiza las predicciones\n",
        "y_pred = best_mlp.predict(X_test)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Calcular sensibilidad (recall)\n",
        "sensitivity = recall_score(y_test, y_pred)\n",
        "print(f'Sensibilidad (Recall): {sensitivity:.4f}')\n",
        "\n",
        "# Calcular especificidad\n",
        "specificity = tn / (tn + fp)\n",
        "print(f'Especificidad: {specificity:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX6hvBJQRPqe",
        "outputId": "83e2885a-46c5-41f1-858a-5a744fdae8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
            "Best parameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (150, 150), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "Best score: 0.8354\n",
            "Final Model Accuracy: 0.8919\n",
            "Final Model Recall: 0.7838\n",
            "Final Model F1 Score: 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARRITMIA       0.82      1.00      0.90        37\n",
            "      NORMAL       1.00      0.78      0.88        37\n",
            "\n",
            "    accuracy                           0.89        74\n",
            "   macro avg       0.91      0.89      0.89        74\n",
            "weighted avg       0.91      0.89      0.89        74\n",
            "\n",
            "Sensibilidad (Recall): 0.7838\n",
            "Especificidad: 1.0000\n"
          ]
        }
      ]
    }
  ]
}