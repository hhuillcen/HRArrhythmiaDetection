{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv('/content/dataset_fc.csv')  #  archivo\n",
        "\n",
        "# Convertir la columna objetivo a datos numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "df['dx_holter_final'] = label_encoder.fit_transform(df['dx_holter_final'])  # 0 para 'arritmia', 1 para 'normal'\n",
        "\n",
        "\n",
        "X = df.drop(columns=['dx_holter_final']).values\n",
        "y = df['dx_holter_final'].values\n",
        "\n",
        "# Imputar valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Balancear los datos antes de dividir\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definir los hiperparámetros a probar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), verbose=2, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Ajustar GridSearchCV a los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best score: {grid_search.best_score_:.4f}')\n",
        "\n",
        "# Evaluar el modelo final con los mejores hiperparámetros\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {accuracy:.4f}')\n",
        "print(f'Final Model Recall: {recall:.4f}')\n",
        "print(f'Final Model F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "\n",
        "# Realiza las predicciones\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Calcular sensibilidad (recall)\n",
        "sensitivity = recall_score(y_test, y_pred)\n",
        "print(f'Sensibilidad (Recall): {sensitivity:.4f}')\n",
        "\n",
        "# Calcular especificidad\n",
        "specificity = tn / (tn + fp)\n",
        "print(f'Especificidad: {specificity:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzXgd4irKkq_",
        "outputId": "559957e5-3d28-4656-dcde-6e1bb1b44f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "Best parameters: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best score: 0.8515\n",
            "Final Model Accuracy: 0.8919\n",
            "Final Model Recall: 0.8378\n",
            "Final Model F1 Score: 0.8857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARRITMIA       0.85      0.95      0.90        37\n",
            "      NORMAL       0.94      0.84      0.89        37\n",
            "\n",
            "    accuracy                           0.89        74\n",
            "   macro avg       0.90      0.89      0.89        74\n",
            "weighted avg       0.90      0.89      0.89        74\n",
            "\n",
            "Sensibilidad (Recall): 0.8378\n",
            "Especificidad: 0.9459\n"
          ]
        }
      ]
    }
  ]
}