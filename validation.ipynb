{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Cargar datos de entrenamiento\n",
        "df = pd.read_csv('/content/dataset_fc.csv')\n",
        "\n",
        "# Convertir la columna objetivo a datos numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "df['dx_holter_final'] = label_encoder.fit_transform(df['dx_holter_final'])  # 0 para 'arritmia', 1 para 'normal'\n",
        "\n",
        "X = df.drop(columns=['dx_holter_final']).values\n",
        "y = df['dx_holter_final'].values\n",
        "\n",
        "# Imputar valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Balancear los datos antes de dividir\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Definir los hiperparámetros a probar\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), verbose=2, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Ajustar GridSearchCV a los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best score: {grid_search.best_score_:.4f}')\n",
        "\n",
        "# Evaluar el modelo final con los mejores hiperparámetros\n",
        "best_dt = grid_search.best_estimator_\n",
        "y_pred = best_dt.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Model Accuracy: {accuracy:.4f}')\n",
        "print(f'Final Model Recall: {recall:.4f}')\n",
        "print(f'Final Model F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Calcular especificidad\n",
        "specificity = tn / (tn + fp)\n",
        "print(f'Final Model Specificity: {specificity:.4f}')\n",
        "\n",
        "# ------------------------------\n",
        "# Validar el conjunto de datos adicional\n",
        "# ------------------------------\n",
        "\n",
        "print (\"----------------------------------------------------\")\n",
        "\n",
        "# Cargar datos de validación\n",
        "df_val = pd.read_csv('/content/validation.csv')  # Ajusta la ruta según el nombre de tu archivo\n",
        "\n",
        "# Convertir la columna objetivo a datos numéricos\n",
        "df_val['dx_holter_final'] = label_encoder.transform(df_val['dx_holter_final'])  # Usar transform para mantener las mismas etiquetas\n",
        "\n",
        "X_val = df_val.drop(columns=['dx_holter_final']).values\n",
        "y_val = df_val['dx_holter_final'].values\n",
        "\n",
        "# Imputar valores faltantes en el conjunto de validación\n",
        "X_val = imputer.transform(X_val)\n",
        "\n",
        "# Normalizar los datos de validación\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Predecir con el modelo entrenado\n",
        "y_val_pred = best_dt.predict(X_val)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
        "print(f'Validation Recall: {val_recall:.4f}')\n",
        "print(f'Validation F1 Score: {val_f1:.4f}')\n",
        "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Calcular la matriz de confusión para el conjunto de validación\n",
        "cm_val = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "#print(cm_val)\n",
        "tn_val, fp_val, fn_val, tp_val = cm_val.ravel()\n",
        "\n",
        "# Calcular especificidad para el conjunto de validación\n",
        "val_specificity = tn_val / (tn_val + fp_val)\n",
        "print(f'Validation Specificity: {val_specificity:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs_t_YStx7V-",
        "outputId": "4b780081-beb1-4061-8714-38fb0d5f48a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
            "Best parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
            "Best score: 0.7925\n",
            "Final Model Accuracy: 0.9324\n",
            "Final Model Recall: 0.9189\n",
            "Final Model F1 Score: 0.9315\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARRITMIA       0.92      0.95      0.93        37\n",
            "      NORMAL       0.94      0.92      0.93        37\n",
            "\n",
            "    accuracy                           0.93        74\n",
            "   macro avg       0.93      0.93      0.93        74\n",
            "weighted avg       0.93      0.93      0.93        74\n",
            "\n",
            "Final Model Specificity: 0.9459\n",
            "----------------------------------------------------\n",
            "Validation Accuracy: 0.7083\n",
            "Validation Recall: 0.9167\n",
            "Validation F1 Score: 0.7586\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARRITMIA       0.86      0.50      0.63        12\n",
            "      NORMAL       0.65      0.92      0.76        12\n",
            "\n",
            "    accuracy                           0.71        24\n",
            "   macro avg       0.75      0.71      0.70        24\n",
            "weighted avg       0.75      0.71      0.70        24\n",
            "\n",
            "[[ 6  6]\n",
            " [ 1 11]]\n",
            "Validation Specificity: 0.5000\n"
          ]
        }
      ]
    }
  ]
}